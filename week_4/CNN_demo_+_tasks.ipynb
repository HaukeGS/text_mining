{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d312eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de3d74d",
   "metadata": {},
   "source": [
    "# Embedding module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daebcb9e",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2e191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.Embedding(num_embeddings, # size of the vocabulary\n",
    "                   embedding_dim, # size of embedding dim\n",
    "                   padding_idx=None, # special token to padding, returns 0 vector\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbaffbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple lookup module but can be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c703c93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the padding id is also included in the vocabulary, \n",
    "# alway add 1 to the size of your vocabulary with the index starting from 1\n",
    "emb = nn.Embedding(10, 20, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba13d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# expects input as a sequence of integers with each representing a particular word...\n",
    "inp_seq = torch.LongTensor([1, 4, 3, 2, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94747f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2826, -0.1858, -0.1663, -0.5926,  0.7455, -0.8056,  0.9270,  1.1362,\n",
       "          0.4072, -1.0552,  0.0958, -0.7895,  0.3323, -0.1014,  0.0308,  1.2783,\n",
       "         -0.3603,  0.2703,  0.0093,  1.9665],\n",
       "        [ 1.1026,  1.6717, -0.0953,  0.5196, -0.6114,  0.2073,  0.2875, -1.5956,\n",
       "          1.5748,  0.0622,  0.6153,  0.0609, -2.6302,  0.3165,  0.0894,  0.0774,\n",
       "          1.6418,  0.8907,  0.7228,  0.2788],\n",
       "        [-0.1668,  0.6591,  2.6490, -0.3813, -1.1069,  1.2718, -0.1496,  0.0862,\n",
       "          0.3578,  0.7714, -1.7435,  1.1185,  0.5483, -1.2257,  1.6306,  1.5401,\n",
       "          1.0606,  0.1643,  0.9296,  0.3183],\n",
       "        [-0.7977,  0.4928,  0.7599, -0.8532,  1.0127, -0.6844,  1.5606, -2.5766,\n",
       "         -0.5283, -0.0092,  1.5554, -0.4958, -1.1682, -0.0657,  0.5264, -0.6802,\n",
       "          0.6588,  0.5126, -0.6077,  1.1235],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000]], grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(inp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb6ba73c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2826, -0.1858, -0.1663, -0.5926,  0.7455, -0.8056,  0.9270,  1.1362,\n",
       "          0.4072, -1.0552,  0.0958, -0.7895,  0.3323, -0.1014,  0.0308,  1.2783,\n",
       "         -0.3603,  0.2703,  0.0093,  1.9665],\n",
       "        [-0.7977,  0.4928,  0.7599, -0.8532,  1.0127, -0.6844,  1.5606, -2.5766,\n",
       "         -0.5283, -0.0092,  1.5554, -0.4958, -1.1682, -0.0657,  0.5264, -0.6802,\n",
       "          0.6588,  0.5126, -0.6077,  1.1235],\n",
       "        [-0.1668,  0.6591,  2.6490, -0.3813, -1.1069,  1.2718, -0.1496,  0.0862,\n",
       "          0.3578,  0.7714, -1.7435,  1.1185,  0.5483, -1.2257,  1.6306,  1.5401,\n",
       "          1.0606,  0.1643,  0.9296,  0.3183],\n",
       "        [ 1.1026,  1.6717, -0.0953,  0.5196, -0.6114,  0.2073,  0.2875, -1.5956,\n",
       "          1.5748,  0.0622,  0.6153,  0.0609, -2.6302,  0.3165,  0.0894,  0.0774,\n",
       "          1.6418,  0.8907,  0.7228,  0.2788],\n",
       "        [ 0.6889,  0.4157, -0.4101, -0.7593, -1.0116,  0.9471,  0.8147, -0.3965,\n",
       "         -1.1963, -0.2805,  1.9783,  0.0031, -0.7325,  0.3185,  1.1306, -0.7068,\n",
       "         -0.1527, -0.5603, -2.3062,  1.9169],\n",
       "        [-0.8986, -0.4475, -0.5227,  1.6705, -0.7408,  1.5829,  0.9592, -1.2700,\n",
       "          0.8679, -2.6118,  0.4460, -0.1404,  1.2729,  2.9611, -1.8980,  0.7484,\n",
       "          0.5019,  0.7402, -0.0404,  0.6249],\n",
       "        [ 0.2958, -0.7404, -0.7955, -0.5197,  0.9784, -0.4578,  1.3546, -0.3114,\n",
       "         -1.1294,  0.4383,  0.5197, -0.2235,  0.2366, -2.0571,  0.0764, -0.6102,\n",
       "         -0.5742,  1.1616,  0.6402,  0.6395],\n",
       "        [-0.3789, -0.1931, -0.5856,  1.6550,  2.5123, -0.8380, -0.0451, -0.5875,\n",
       "         -0.1544, -0.0749,  0.0181, -0.0181,  0.3214,  0.5381, -1.7750, -0.7187,\n",
       "          2.5124, -1.2887,  0.5835,  0.6868],\n",
       "        [-1.1601, -0.4245, -0.1248, -0.6429, -0.7286, -0.3407,  0.7018, -0.0849,\n",
       "          0.6301,  0.9193, -0.3802, -0.8063, -0.2430, -1.3713,  0.5091,  1.7891,\n",
       "         -0.6098, -0.3149,  0.0845, -0.5934]], requires_grad=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2823e849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 20])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92db281e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to freeze the embedding layer set emb.weight.requires_grad to False\n",
    "emb.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6d96307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0000, 5.1000, 6.3000]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FloatTensor containing pretrained weights\n",
    "weight = torch.FloatTensor([[1, 2.3, 3], [4, 5.1, 6.3]])\n",
    "embedding = nn.Embedding.from_pretrained(weight)\n",
    "# Get embeddings for index 1\n",
    "input = torch.LongTensor([1])\n",
    "embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2e4407f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.weight.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79a61f",
   "metadata": {},
   "source": [
    "# CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10388b5e",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016ea52c",
   "metadata": {},
   "source": [
    "https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b9c81",
   "metadata": {},
   "source": [
    "Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665c73a",
   "metadata": {},
   "source": [
    "MaxPool2d(kernel_size, stride=None, padding=0) # default stride = kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70f11e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((1, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b716556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Convnet,self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(1,8,5) # n1 = 8 # for convolution operation\n",
    "        # input is of size 224 x 224\n",
    "        # width/height output = (224 - 5) + 1 = 220, output = 8 x 220 x 220 \n",
    "        # after maxpool operation: output: 8 x 110 x 110\n",
    "        self.conv_2 = nn.Conv2d(8,16,5) # n2 = 16\n",
    "        # input is of size 8 x 110 x 110\n",
    "        # width/height output = (110 - 5) + 1 = 106, output = 16 x 106 x 106 \n",
    "        # after maxpool operation: output: 16 x 53 x 53\n",
    "        self.maxpool = nn.MaxPool2d(2,2) # for pooling operation\n",
    "        self.fc_3 = nn.Linear(16*53*53,128)\n",
    "        self.fc_4 = nn.Linear(128,1)\n",
    "        self.relu = nn.ReLU() # Activation function\n",
    "        \n",
    "    def forward(self,inp):\n",
    "        out = self.conv_1(inp)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = self.conv_2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "        out = out.reshape(inp.shape[0],-1) # flatten the output, first argument is batch-size\n",
    "        out = self.fc_3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc_4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e833ed7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Convnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74f46df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0295]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b532a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about batching\n",
    "inp = torch.randn((10, 1, 224, 224)) # First dimension is the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0349236b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0439],\n",
       "        [-0.0116],\n",
       "        [-0.0440],\n",
       "        [-0.0400],\n",
       "        [ 0.0300],\n",
       "        [-0.0292],\n",
       "        [-0.0447],\n",
       "        [-0.0310],\n",
       "        [-0.0072],\n",
       "        [-0.0750]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2203c3c",
   "metadata": {},
   "source": [
    "<img src=\"cnns_text.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dfee64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.randn((5, 1, 10, 20)) # 10 words each with an embedding size of 20, batch size 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "981fa6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv2 = nn.Conv2d(1, 30, kernel_size=(5, 20)) # the second dimension of the filter is of the size of embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58d48d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = conv2(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "40ff1cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 30, 6, 1])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2(inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2baa68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxpool = nn.MaxPool2d((2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ca35940",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = maxpool(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d0f11bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 30, 3, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce0fe20",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea94283",
   "metadata": {},
   "source": [
    "We will train a CNN based classifier for the sentiment classification task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "91e97bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b629eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sentiment/sentiment_train_X.p', 'rb') as fs:\n",
    "    train_data = pickle.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e24cbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Rock',\n",
       " 'is',\n",
       " 'destined',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " '21st',\n",
       " 'Century',\n",
       " \"'s\",\n",
       " 'new',\n",
       " '``',\n",
       " 'Conan',\n",
       " '``',\n",
       " 'and',\n",
       " 'that',\n",
       " 'he',\n",
       " \"'s\",\n",
       " 'going',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'splash',\n",
       " 'even',\n",
       " 'greater',\n",
       " 'than',\n",
       " 'Arnold',\n",
       " 'Schwarzenegger',\n",
       " ',',\n",
       " 'Jean-Claud',\n",
       " 'Van',\n",
       " 'Damme',\n",
       " 'or',\n",
       " 'Steven',\n",
       " 'Segal',\n",
       " '.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d106b622",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sentiment/sentiment_train_y.p', 'rb') as fs:\n",
    "    train_label = pickle.load(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ba1d857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c014437",
   "metadata": {},
   "source": [
    "1) Considering all the unique words present in the training data as your vocabulary create a word2index mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008e46ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "429725b1",
   "metadata": {},
   "source": [
    "2) Write a function which takes as input an input takes and returns a list of ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc73f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input = ['The', 'movie', 'is', 'good']\n",
    "# output = [10, 15, 2, 4]\n",
    "# Note that the vocabulary is only made of words in the train set which mean in the val and test set \n",
    "# you may encounter new words. You can ignore such words and make sure your function is capable of handling it.\n",
    "def text2ids():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6672525",
   "metadata": {},
   "source": [
    "3) Write a pytorch dataset class for the sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c68ab861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab43c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We were selecting batches previously by creating a generator (Week 2 exercise)\n",
    "# Pytorch provides a dataset class which allows you to do this in an easier way\n",
    "# Takes care of the sampling a batch from the training data\n",
    "# Allows you to shuffle the data at the end of each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "112d9b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 6920)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed45f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentData(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.label) # should return the size of the data\n",
    "    \n",
    "    def __getitem__(self, index): # returns on training instance (x, y)\n",
    "        inp_text = self.data[index]\n",
    "        label = self.label[index]\n",
    "        input_ids = text2ids(inp_text) # execute preprocess code here\n",
    "        return torch.LongTensor(input_ids), torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eb9b39",
   "metadata": {},
   "source": [
    "2) Design a CNN based text classifier mode. It should include a embedding module which should be initialized randomly and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36259980",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a44762",
   "metadata": {},
   "source": [
    "3) Train the model for 10 epochs. At the end of each epoch, compute validation accuracy and save the model with the best validation accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb02e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131c9b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_accuracy = 0\n",
    "model = Classifier()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCEWithLogitsLoss() # Compute only the logits i.e., no sigmoid in the last layer\n",
    "train_d = SentimentData(train_data, train_label)\n",
    "val_d = SentimentData(val_data, val_label)\n",
    "train_loader = DataLoader(train_d, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_d, batch_size=16, shuffle=True)\n",
    "epochs = 10\n",
    "for e in range(epochs):\n",
    "    for X, y in train_loader:\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # At the end of each epoch, we compute the validation accuracy\n",
    "    model.eval() # set the model in eval mode\n",
    "    for X, y in val_loader:\n",
    "        out = model(X)\n",
    "        # output will be logits\n",
    "        out = torch.sigmoid(out) # map it to a value between 0 and 1\n",
    "        # we need to now map to a class >=0.5 is 1 and <0.5 is 0\n",
    "        # Use torch.round\n",
    "        # Compare with the ground-truth\n",
    "        # Note that the output will be calculated over a batch\n",
    "        # Collect the output and the ground-truth class over all the batches\n",
    "     \n",
    "    accuracy = accuracy(ground_truth, predicted)\n",
    "    if accuracy>max_accuracy:\n",
    "        # save model\n",
    "        torch.save(clf.state_dict(), 'best_model.pt')\n",
    "    model.train() # revert back to training mode for the next epoch    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7074b7",
   "metadata": {},
   "source": [
    "4) Evaluate the model on the test set and report the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28ee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = Classifier()\n",
    "best_model.load_state_dict(torch.load('best_model.pt')) # load the best trained model i.e., one with the highest val acc\n",
    "test_d = SentimentData(test_data, test_label)\n",
    "test_loader = DataLoader(test_d, batch_size=16, shuffle=True)\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad(): # gradients won't be calculated, saves memory\n",
    "    for X, y in test_loader:\n",
    "        # pretty much the same lines of code as in validation\n",
    "        pass\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
