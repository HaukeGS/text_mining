{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c5bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk\n",
    "#conda install nltk\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e672ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa189a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087dc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184da23",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893bec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Python is a programing language. We are learning python.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d614083",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847359c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520b1bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Mr. Python is a programing language. We are learning python.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc07532",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ed2d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf30b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de25645",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdc597b",
   "metadata": {},
   "source": [
    "# Text normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bec1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48934d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c32b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c63d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ffa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens_f = [w for w in text_tokens if w not in puncts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f93ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ddbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19bff9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325d9ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dac048",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24a802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens_f = [w for w in text_tokens_f if w.lower() not in s_words]\n",
    "# [w for w in text_tokens_f if w.lower() not in s_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d533978f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037141ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer #worked -> work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105779e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11af35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31363351",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.stem('leaves')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d922685b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77dc083",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl.lemmatize('leaves')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd16231",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d79912",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d3f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mma = nltk.corpus.gutenberg.words('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b848542",
   "metadata": {},
   "outputs": [],
   "source": [
    "mma[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57a29b1",
   "metadata": {},
   "source": [
    "1) Lemmatize all the tokens in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c770ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preview(a: list):\n",
    "    print(len(a))\n",
    "    print(a[:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae37ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = [wnl.lemmatize(w) for w in mma]\n",
    "print_preview(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa19a03e",
   "metadata": {},
   "source": [
    "2) Remove all stop words from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372693df",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_stop_words = [w for w in lemmas if w not in s_words]\n",
    "print_preview(no_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310eae4c",
   "metadata": {},
   "source": [
    "3) Find all the unique tokens in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca0475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = list(set(no_stop_words))\n",
    "print_preview(uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb691253",
   "metadata": {},
   "source": [
    "4) Create a mapping word2index which maps every unique token to an integer index. Create a reverse mapping index2word.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_uniques = sorted(uniques)\n",
    "print_preview(sorted_uniques)\n",
    "word2index = {sorted_uniques[index]: index for index in range(len(sorted_uniques))}\n",
    "index2word = {index: word for word, index in word2index.items()}\n",
    "print(index2word.get(0))\n",
    "print(word2index.get(\"Am\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64e585c",
   "metadata": {},
   "source": [
    "5) Considering a window size of 3, create a token-token frequency matrix where each cell notes the frequency of occurrence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e834265",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_matrix = [[0 for j in range(len(uniques))] for i in range(len(uniques))]\n",
    "print(len(frequency_matrix))\n",
    "print(len(frequency_matrix[0]))\n",
    "for i, word in enumerate(mma):\n",
    "    if word not in uniques:\n",
    "        continue\n",
    "    context = mma[max(i-3,0):i] + mma[i+1:min(i+4,len(mma))]\n",
    "    for context_word in context:\n",
    "        if context_word in uniques:\n",
    "            frequency_matrix[word2index.get(word)][word2index.get(context_word)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a891bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frequency_matrix[:10][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d91b5",
   "metadata": {},
   "source": [
    "6) Compute Positive pointwise mutual information for each token pair in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb75690",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = [\n",
    "    [0, 0, 1, 0, 1],\n",
    "    [0, 0, 1, 0, 2],\n",
    "    [2, 1, 0, 1, 0],\n",
    "    [1, 6, 0, 4, 0],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a49030",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_matrix = frequency_matrix\n",
    "\n",
    "sum_of_all_entries = sum([sum(a) for a in frequency_matrix])\n",
    "sum_rows = [sum(frequency_matrix[i]) for i in range(len(frequency_matrix))]\n",
    "sum_columns = [sum([frequency_matrix[i][j] for i in range(len(frequency_matrix))]) for j in range(len(frequency_matrix[0]))]\n",
    "\n",
    "print(sum_of_all_entries)\n",
    "print(sum_rows[:10])\n",
    "print(sum_columns[:10])\n",
    "\n",
    "def get_P_wi(i: int):\n",
    "    sum_row = sum_rows[i]\n",
    "    return sum_row / sum_of_all_entries\n",
    "\n",
    "def get_P_cj(j: int):\n",
    "    sum_column = sum_columns[j]\n",
    "    return sum_column / sum_of_all_entries\n",
    "\n",
    "def get_P_wi_cj(i: int, j: int):\n",
    "    return frequency_matrix[i][j] / sum_of_all_entries\n",
    "\n",
    "def calculate_pmi(i: int, j: int):\n",
    "    try:\n",
    "        numerator = get_P_wi_cj(i, j)\n",
    "        denominator = (get_P_wi(i) * get_P_cj(j))\n",
    "        if denominator == 0 or numerator == 0:\n",
    "            return 0\n",
    "        return math.log2(numerator / denominator)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception: {e}\")\n",
    "        print(f\"Denominator: {denominator}\")\n",
    "\n",
    "def calculate_ppmi(i: int, j: int):\n",
    "    return max(calculate_pmi(i, j), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1287d162",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppmi = calculate_ppmi(0, 0)\n",
    "print(ppmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9132c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppmi_matrix = [[0.0 for j in range(len(frequency_matrix[i]))] for i in range(len(frequency_matrix))]\n",
    "ppmi_matrix = [[0.0 for j in range(1000)] for i in range(1000)]\n",
    "\n",
    "for i in range(len(ppmi_matrix)):\n",
    "    for j in range(len(ppmi_matrix[i])):\n",
    "        print(f\"Calculating ppmi for {i}, {j}\")\n",
    "        ppmi_matrix[i][j] = calculate_ppmi(i, j)\n",
    "\n",
    "print(ppmi_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e408bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
