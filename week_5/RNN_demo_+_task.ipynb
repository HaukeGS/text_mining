{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbf4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2972ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042c5fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mma = nltk.corpus.gutenberg.sents('austen-emma.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07be1a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7717"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647fdc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['But',\n",
       " 'James',\n",
       " 'will',\n",
       " 'not',\n",
       " 'like',\n",
       " 'to',\n",
       " 'put',\n",
       " 'the',\n",
       " 'horses',\n",
       " 'to',\n",
       " 'for',\n",
       " 'such',\n",
       " 'a',\n",
       " 'little',\n",
       " 'way',\n",
       " ';--',\n",
       " 'and',\n",
       " 'where',\n",
       " 'are',\n",
       " 'the',\n",
       " 'poor',\n",
       " 'horses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'while',\n",
       " 'we',\n",
       " 'are',\n",
       " 'paying',\n",
       " 'our',\n",
       " 'visit',\n",
       " '?\"']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mma[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb88207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86f51a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d80d5dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in mma:\n",
    "    for w in sent:\n",
    "        vocab[w]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463c6d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7806"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce529457",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1 # index 0 will be kept for padding\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "for w in vocab:\n",
    "    if vocab[w]>5:\n",
    "        word2index[w] = i\n",
    "        index2word[i] = w\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f3e27b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2169"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7aa213f",
   "metadata": {},
   "source": [
    "# RNN Language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdfc197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 256\n",
    "        self.vocab_size = 2170\n",
    "        self.emb_dim = 100\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(self.emb_dim, self.hidden_size) # input_dimension, hidden_dimension\n",
    "        self.lin = nn.Linear(self.hidden_size, self.vocab_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inp_seq):\n",
    "        inp = self.emb(inp_seq)\n",
    "        h_0 = torch.rand(1, self.hidden_size)\n",
    "        all_hidden_states, last_hidden_state = self.rnn(inp, h_0)\n",
    "        out = self.lin(all_hidden_states)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5974d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM = RNN_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50f7d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = mma[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e23eb1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['But',\n",
       " 'James',\n",
       " 'will',\n",
       " 'not',\n",
       " 'like',\n",
       " 'to',\n",
       " 'put',\n",
       " 'the',\n",
       " 'horses',\n",
       " 'to',\n",
       " 'for',\n",
       " 'such',\n",
       " 'a',\n",
       " 'little',\n",
       " 'way',\n",
       " ';--',\n",
       " 'and',\n",
       " 'where',\n",
       " 'are',\n",
       " 'the',\n",
       " 'poor',\n",
       " 'horses',\n",
       " 'to',\n",
       " 'be',\n",
       " 'while',\n",
       " 'we',\n",
       " 'are',\n",
       " 'paying',\n",
       " 'our',\n",
       " 'visit',\n",
       " '?\"']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43605e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ind = [word2index[w] for w in seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3a6e3b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[418,\n",
       " 452,\n",
       " 453,\n",
       " 146,\n",
       " 454,\n",
       " 19,\n",
       " 455,\n",
       " 22,\n",
       " 456,\n",
       " 19,\n",
       " 66,\n",
       " 247,\n",
       " 13,\n",
       " 37,\n",
       " 132,\n",
       " 411,\n",
       " 10,\n",
       " 419,\n",
       " 457,\n",
       " 22,\n",
       " 458,\n",
       " 456,\n",
       " 19,\n",
       " 212,\n",
       " 459,\n",
       " 429,\n",
       " 457,\n",
       " 460,\n",
       " 461,\n",
       " 322,\n",
       " 417]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e3a0ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_ind = torch.LongTensor(seq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67a06ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = LM(seq_ind) # generates hidden states corresponding to each input in the sequence...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90e4251f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 2170])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fe39dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b363429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the loss --\n",
    "\n",
    "# Output distribution from the first token should be able to predict the second one\n",
    "\n",
    "# Output distribution from the second token should be able to predict the third one\n",
    "\n",
    "# ...and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "971614bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second token is the ground-truth for the first\n",
    "\n",
    "# third token is the ground-truth for the second\n",
    "\n",
    "# ...and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bce56f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth would be the sequence starting from the second token... we ignore the first...\n",
    "\n",
    "# similarly the output from the last token in the sequence is not needeed as there is no token following it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8065c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "output = LM(seq_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ded8e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lm = output[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3f6db4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 2170])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c1783bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = seq_ind[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c38acfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8fe6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7f037f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_lm = softmax(output_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "028891f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.7225, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(output_lm.squeeze(0), labels.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764fd0a",
   "metadata": {},
   "source": [
    "# Generate new sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d69dd542",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "seq = [418] # index corresponding to 'But'\n",
    "for _ in range(seq_len):\n",
    "    out = LM(torch.IntTensor(seq))\n",
    "    #next_token = torch.argmax(out[], dim=1)\n",
    "    #seq.append\n",
    "    out = out[-1,:]\n",
    "    next_token = torch.argmax(out)\n",
    "    seq.append(next_token.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a4c5891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[418, 1676, 1609, 1989, 1701, 284, 1854, 1076, 558, 634, 81]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4d626ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But unpleasant gradually resumed intention suffering escaped inferior dreadfully should Miss'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([index2word[i] for i in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095a507",
   "metadata": {},
   "source": [
    "# RNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5d38d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = 256\n",
    "        self.vocab_size = 2170\n",
    "        self.emb_dim = 100\n",
    "        self.out_size = 2\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(self.emb_dim, self.hidden_size) # input_dimension, hidden_dimension\n",
    "        self.lin = nn.Linear(self.hidden_size, self.out_size)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, inp_seq):\n",
    "        inp = self.emb(inp_seq)\n",
    "        h_0 = torch.rand(1, self.hidden_size)\n",
    "        all_hidden_states, last_hidden_state = self.rnn(inp, h_0)\n",
    "        out = self.lin(last_hidden_state)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "102495a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RNN_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "910a3874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3353, 0.1334]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf(seq_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c29792",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ed7110",
   "metadata": {},
   "source": [
    "We will design a language model with this vanilla RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9237e4",
   "metadata": {},
   "source": [
    "1) Train the language model considering all the sentences in the corpus. Each training step will include one sentence. Ignore all sentences with length 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a85fb6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67cae220",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f7b4c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bff6ca511f24dc4b5666909f3240c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7717 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = Adam(LM.parameters(), lr=0.001)\n",
    "for _ in range(epochs):\n",
    "    for seq in tqdm(mma):\n",
    "        seq_ind = [word2index[w] for w in seq if w in word2index]\n",
    "        if len(seq_ind)>1:\n",
    "            seq_ind = torch.LongTensor(seq_ind)\n",
    "            output = LM(seq_ind)\n",
    "            output_lm = output[:-1,:]\n",
    "            labels = seq_ind[1:]\n",
    "            output_lm = torch.log_softmax(output_lm, dim=1)\n",
    "            loss = criterion(output_lm.squeeze(0), labels.squeeze(0))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c796c6",
   "metadata": {},
   "source": [
    "2) Use the model to generate some example sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04fab9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "seq = [418] # index corresponding to 'But'\n",
    "for _ in range(seq_len):\n",
    "    out = LM(torch.IntTensor(seq))\n",
    "    #next_token = torch.argmax(out[], dim=1)\n",
    "    #seq.append\n",
    "    out = out[-1,:]\n",
    "    next_token = torch.argmax(out)\n",
    "    seq.append(next_token.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "279116ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'But , and the of the of her , and ,'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([index2word[i] for i in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cbfe24",
   "metadata": {},
   "source": [
    "3) Design a RNN based classifier model for the task of sentiment classification. Use the sentiment classification dataset from last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59da217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The architecture is already provided. Use the code from previous weeks to train/evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f10f49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
