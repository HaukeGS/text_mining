{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4927fefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        #corpus_path = datapath('abc_news/abcnews-date-text.csv')\n",
    "        for line in open('abc_news/abcnews-date-text.csv'):\n",
    "            ind = line.find(\",\")                   \n",
    "            text = line[ind+1:]                   \n",
    "            yield utils.simple_preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f618421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = MyCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3475ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aba', 'decides', 'against', 'community', 'broadcasting', 'licence']\n",
      "['act', 'fire', 'witnesses', 'must', 'be', 'aware', 'of', 'defamation']\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for s in sentences:\n",
    "    print(s)\n",
    "    i+=1\n",
    "    if i==2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291fcf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2bc74de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a few minutes...\n",
    "model = gensim.models.Word2Vec(sentences=sentences) #min_count=5, vector_size=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ca6088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38684"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48e2db7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word #0 is to\n",
      "word #1 is in\n",
      "word #2 is for\n",
      "word #3 is of\n",
      "word #4 is on\n",
      "word #5 is the\n",
      "word #6 is over\n",
      "word #7 is police\n",
      "word #8 is at\n",
      "word #9 is with\n"
     ]
    }
   ],
   "source": [
    "for index, word in enumerate(model.wv.index_to_key):\n",
    "    if index == 10:\n",
    "        break\n",
    "    print(f\"word #{index} is {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a63527d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.876929  ,  0.36573046, -0.04436797, -0.2312297 , -0.23336677,\n",
       "        1.5372736 ,  1.6806175 ,  1.4925967 , -0.70252985, -1.3188128 ,\n",
       "        1.2768271 ,  0.51103354, -0.61636156,  0.20204471,  1.8007569 ,\n",
       "        1.0954375 ,  2.4577975 ,  1.4593645 ,  0.37467524, -1.1313852 ,\n",
       "        0.3397876 ,  1.6261564 ,  0.54296994, -1.0222702 , -2.9926198 ,\n",
       "       -0.3150511 , -0.8980939 ,  0.7713534 , -0.27746835,  0.6877973 ,\n",
       "       -0.7031958 , -0.28893924, -1.3481305 ,  0.68166167, -0.4411558 ,\n",
       "        0.15603477, -2.4622796 , -1.3708696 ,  0.47186565,  1.5288067 ,\n",
       "        0.3202819 , -0.31492466,  0.20830353, -1.094427  , -1.3252416 ,\n",
       "        1.6239321 , -0.9848096 ,  1.0463514 ,  0.5173541 , -1.6201061 ,\n",
       "       -0.5579231 , -1.2227696 ,  1.8716978 , -1.770485  ,  1.1623493 ,\n",
       "       -0.45479202, -3.1006906 , -0.00998674,  1.1050769 ,  0.6193704 ,\n",
       "        1.292312  , -1.2837234 ,  0.65003306,  1.5189573 ,  1.0474945 ,\n",
       "        0.35978016, -2.854416  , -1.2052798 , -0.82887965, -0.04145707,\n",
       "        0.86823666, -2.2740245 ,  0.05284162, -1.4627304 , -0.81753486,\n",
       "        1.2265306 ,  1.4230263 , -1.5636116 ,  2.7156818 , -0.7856085 ,\n",
       "       -1.0233166 ,  0.869933  , -0.72073615,  0.34415376,  0.33679473,\n",
       "        0.394619  ,  1.4958502 ,  0.7201203 ,  1.6393889 , -0.09692207,\n",
       "        2.9089682 , -4.478792  , -2.2662387 ,  1.9514847 , -1.2622408 ,\n",
       "       -0.85439587, -2.6642656 , -1.4420116 ,  3.54718   , -2.1708052 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['police']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a4e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('detectives', 0.7062063217163086), ('afp', 0.6775110960006714), ('authorities', 0.6539719700813293), ('customs', 0.5348871350288391), ('qps', 0.5265768766403198)]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.most_similar(positive=['police'], topn=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec60e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will require a few GBs of RAM ()\n",
    "import gensim.downloader as api\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe1e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# man:woman :: king:?\n",
    "# man - woman = king - ?\n",
    "# ? = woman - man + king\n",
    "# we add woman and king and subtract man\n",
    "# positive=['king', 'woman'] and negative=['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1bf279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.7118193507194519),\n",
       " ('monarch', 0.6189674139022827),\n",
       " ('princess', 0.5902431011199951),\n",
       " ('crown_prince', 0.5499460697174072)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['king', 'woman'], negative=['man'], topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc972e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Berlin', 0.7644002437591553),\n",
       " ('Frankfurt', 0.7329736351966858),\n",
       " ('Dusseldorf', 0.7009456753730774),\n",
       " ('Munich', 0.6773864030838013)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.most_similar(positive=['Germany', 'Paris'], negative=['France'], topn=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17fbfb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd8f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine(a,b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd775abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51210403"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine(wv['tiger'], wv['lion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8286773",
   "metadata": {},
   "source": [
    "# GLoVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcc28d6",
   "metadata": {},
   "source": [
    "<img src=\"glove_loss.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f060df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "373e37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "87d016fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Glove(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "        self.W_hat = nn.Parameter(torch.randn(vocab_size, embed_dim))\n",
    "        self.b = nn.Parameter(torch.randn(vocab_size, 1))\n",
    "        self.b_hat = nn.Parameter(torch.randn(vocab_size, 1))\n",
    "        self.x_max = 100\n",
    "    \n",
    "    def normalize(self, x):\n",
    "        return (x/self.x_max)**0.75\n",
    "    \n",
    "    def forward(self, w_i, w_j, x_ij):\n",
    "        emb_1 = self.W[w_i]\n",
    "        emb_2 = self.W_hat[w_j]\n",
    "        prod = torch.sum(emb_1*emb_2, dim=1)\n",
    "        out = torch.pow(prod + self.b[w_i] + self.b_hat[w_j] - torch.log(x_ij),2)\n",
    "        return out*self.normalize(x_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "55529a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Glove(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "253e4208",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1 = torch.LongTensor([0, 1])\n",
    "w_2 = torch.LongTensor([1, 2])\n",
    "x_12 = torch.LongTensor([1, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bcf16222",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(w_1, w_2, x_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "aa664e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5858e9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.mean(out)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7493a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "850603e8",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff71230",
   "metadata": {},
   "source": [
    "1) Check out the documentation from Gensim for fasttext and doc2vec and try out these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773176ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05ba4254",
   "metadata": {},
   "source": [
    "2) Down load the word analogy dataset from http://download.tensorflow.org/data/questions-words.txt\n",
    "\n",
    "Example: Athens Greece Baghdad Iraq\n",
    "\n",
    "Frame the analogy question as Athens:Greece :: Baghdad: x\n",
    "\n",
    "Using the pre-trained word2vec model predict x. Check if x is correctly predicted.\n",
    "\n",
    "Do this across all the examples and report the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f8cce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "726ab8dd",
   "metadata": {},
   "source": [
    "3) Consider the GOT corpus from last week's exercise. Create a word-word co-occurrence matrix (do the necessary pre-processing) and train the GLoVe model on this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1a0da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range(epochs):\n",
    "    for W_i, W_j, X_ij in batches:\n",
    "        # Fill this out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_mining_week3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
